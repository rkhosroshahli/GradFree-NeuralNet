{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.gfo import GFOProblem, SOCallback, blocker, build_rand_blocks, get_model_params, set_model_state\n",
    "\n",
    "# Train on MNIST\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "            f1_score,\n",
    "        )\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    f1 = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            f1 += f1_score(target.view_as(pred).cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "\n",
    "\n",
    "    return total_loss / len(test_loader), correct / len(test_loader.dataset), f1 / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmaes import CMA\n",
    "\n",
    "# Parameter Setting\n",
    "NP = 100\n",
    "block_size = 1000\n",
    "# Define model\n",
    "model = MLP()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "init_params = get_model_params(model)\n",
    "D = len(init_params)\n",
    "print(f\"Original dims: {D} D\")\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "\n",
    "codebook = {}\n",
    "if os.path.exists(f'out/codebook_D{D}_blocksize{block_size}.pkl'):\n",
    "    with open(f'out/codebook_D{D}_blocksize{block_size}.pkl', 'rb') as f:\n",
    "        codebook = pickle.load(f)\n",
    "else:\n",
    "    codebook = build_rand_blocks(D, block_size=block_size)\n",
    "    \n",
    "    with open(f'out/codebook_D{D}_blocksize{block_size}.pkl', 'wb') as f:\n",
    "        pickle.dump(codebook, f)\n",
    "\n",
    "bD = len(codebook)\n",
    "print(f\"Blocked dims: {bD} D\")\n",
    "x0 = np.random.uniform(low=-1, high=1, size=(bD))\n",
    "init_params = blocker(init_params, codebook)\n",
    "# x0 = init_params.copy()\n",
    "# init_pop = np.random.normal(loc=init_params, scale=0.1, size=(NP, bD))\n",
    "\n",
    "# random_indices = np.random.choice(\n",
    "#             np.arange(len(trainset)), size=1024, replace=False\n",
    "#         )\n",
    "# random_dataset = Subset(trainset, random_indices)\n",
    "# data_loader = DataLoader(random_dataset, batch_size=128, shuffle=True)\n",
    "data_loader = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "problem = GFOProblem(n_var=bD, model=model, dataset=trainset, test_loader=test_loader, train_loader=data_loader, \n",
    "                      set_model_state=set_model_state,\n",
    "                      batch_size=1024, device=device, criterion=\"f1\",\n",
    "                      block=True, codebook=codebook, orig_dims=D)\n",
    "out={\"F\": []}\n",
    "problem._evaluate(np.array([x0, init_params]), out=out)\n",
    "print(out)\n",
    "\n",
    "csv_path = f\"out/MLP_block_bs{block_size}_gfo_f1_1024data_cmaesv2_5restart_hist.csv\"\n",
    "plt_path = f\"out/MLP_block_bs{block_size}_gfo_f1_1024data_cmaesv2_5restart_plt.pdf\"\n",
    "df = pd.DataFrame({\n",
    "            'n_step': [0],\n",
    "            'n_eval': [1],\n",
    "            'f_best': [out[\"F\"][0]],\n",
    "            'f_avg': [out[\"F\"][0]],\n",
    "            'f_std': [0],\n",
    "            'test_f1_best': problem.test_func(x0),\n",
    "        })\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "callback = SOCallback(k_steps=100, csv_path=csv_path, plt_path=plt_path)\n",
    "n_restarts = 5\n",
    "adp_sigma = 0.1\n",
    "for i_res in range(n_restarts):\n",
    "    optimizer = CMA(mean=x0, sigma=adp_sigma)\n",
    "    evals = 0\n",
    "    steps = 0\n",
    "    best_X, best_F = None, None\n",
    "    while evals < 10000:\n",
    "        steps += 1\n",
    "        solutions=[]\n",
    "        for pi in range(optimizer.population_size):\n",
    "            x = optimizer.ask()\n",
    "            fitness = problem.scipy_fitness_func(x)\n",
    "            evals += 1\n",
    "            solutions.append((x, fitness))\n",
    "\n",
    "        solutions.sort(key=lambda s: s[1])\n",
    "        pop_F = [s[1] for s in solutions]\n",
    "        best_X, best_F = solutions[0][0], solutions[0][-1]\n",
    "        print(f\"step: {steps}, FE: {evals}, f_min: {best_F:.6f}, f_avg: {np.mean(pop_F):.6f}\")\n",
    "\n",
    "        optimizer.tell(solutions)\n",
    "    \n",
    "    x0 = best_X.copy()\n",
    "    adp_sigma *= 0.1\n",
    "\n",
    "    if i_res < n_restarts:\n",
    "        print(\"Restart optimizer...\")\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (best_X, best_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
